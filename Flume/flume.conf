
# https://flume.apache.org/FlumeUserGuide.html#hdfs-sink

agent_review.sources          = http-api-source1
agent_review.sinks            = hdfs-sink1 spark-sink1  # console-sink1 
agent_review.channels         = mem-channel-1 mem-channel-2

## SOURCE
#<Agent>.sources.<Source>.<someProperty> = <someValue>
agent_review.sources.http-api-source1.type                  = http
agent_review.sources.http-api-source1.bind                  = 0.0.0.0
agent_review.sources.http-api-source1.port                  = 9001

## CHANNEL
#<Agent>.channel.<Channel>.<someProperty> = <someValue>
agent_review.channels.mem-channel-1.type                    = memory
# The maximum number of events stored in the channel
agent_review.channels.mem-channel-1.capacity                = 1000
# The maximum number of events the channel will take from a source or give to a sink per transaction
agent_review.channels.mem-channel-1.transactionCapacity     = 100
agent_review.channels.mem-channel-2.type                    = memory
agent_review.channels.mem-channel-2.capacity                = 1000
agent_review.channels.mem-channel-2.transactionCapacity     = 100

## SINK
#<Agent>.sources.<Sink>.<someProperty> = <someValue>

# SINK hdfs-sink1
agent_review.sinks.hdfs-sink1.type                          = hdfs
# HDFS directory path (eg hdfs://namenode/flume/webdata/)
agent_review.sinks.hdfs-sink1.hdfs.path                     = hdfs://lambda-pluralsight:9000/flume/yelp/%Y-%m-%d
#agent_review.sinks.hdfs-sink1.hdfs.path                     = /user/cloudera/loudacre/yelp/logs/%Y-%m-%d
agent_review.sinks.hdfs-sink1.hdfs.useLocalTimeStamp        = true
# Name prefixed to files created by Flume in hdfs directory
agent_review.sinks.hdfs-sink1.hdfs.filePrefix               = events-%H%M
# Format for sequence file records. One of Text or Writable.
# Set to Text before creating data files with Flume,
# otherwise those files cannot be read by either Apache Impala (incubating) or Apache Hive.
agent_review.sinks.hdfs-sink1.hdfs.writeFormat              = Text
# File format: currently SequenceFile, DataStream or CompressedStream
# (1)DataStream will not compress output file and please don’t set codeC
# (2)CompressedStream requires set hdfs.codeC with an available codeC
agent_review.sinks.hdfs-sink1.hdfs.fileType                 = DataStream
agent_review.sinks.hdfs-sink1.hdfs.round                    = true
agent_review.sinks.hdfs-sink1.hdfs.roundValue               = 1
agent_review.sinks.hdfs-sink1.hdfs.roundUnit                = minute
# Rolling file config
agent_review.sinks.hdfs-sink1.hdfs.rollSize                 = 10240
agent_review.sinks.hdfs-sink1.hdfs.rollInterval             = 0
agent_review.sinks.hdfs-sink1.hdfs.rollCount                = 0

# SINK spark-sink1
# This sink forms one half of Flume’s tiered collection support.
# Flume events sent to this sink are turned into Avro events and sent to the configured hostname / port pair.
# The events are taken from the configured Channel in batches of the configured batch size.
# hostname      : hostname or IP address to bind to.
# port          : port # to listen on.
# batch-size    : number of event to batch together for send. default = 100
agent_review.sinks.spark-sink1.type                         = avro
agent_review.sinks.spark-sink1.hostname                     = lambda-pluralsight
agent_review.sinks.spark-sink1.port                         = 8122
agent_review.sinks.spark-sink1.batch-size                   = 10

# SINK : for spark pulling
#agent_review.sinks.spark-sink1.type                         = org.apache.spark.streaming.flume.sink.SparkSink
#agent_review.sinks.spark-sink1.hostname                     = localhost
#agent_review.sinks.spark-sink1.port                         = 8122
#agent_review.sinks.spark-sink1.batch-size                   = 2

# SINK : console-sink1
# maxBytesToLog : Maximum number of bytes of the Event body to log
#agent_review.sinks.console-sink1.type                      = logger
#agent_review.sinks.console-sink1.maxBytesToLog             = 30

## FLOW CONFIGURATION
# set list of channels for source
agent_review.sources.http-api-source1.channels              = mem-channel-1 mem-channel-2
agent_review.sources.http-api-source1.selector.type         = replicating

# set channel for sinks
agent_review.sinks.hdfs-sink1.channel                       = mem-channel-1
agent_review.sinks.spark-sink1.channel                      = mem-channel-2

# DEBUG with console print
#agent_review.sinks.console-sink1.channel                    = mem-channel-1